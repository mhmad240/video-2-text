import streamlit as st
import tempfile
import os
import time
import sys

# Force UTF-8 encoding for stdout/stderr
if sys.stdout.encoding != 'utf-8':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except AttributeError:
        pass

# ุฅุถุงูุฉ ูุณุงุฑ ูุฌูุฏ modules ูุฏููุงู
current_dir = os.path.dirname(os.path.abspath(__file__))
modules_path = os.path.join(current_dir, 'modules')
sys.path.insert(0, modules_path)

# ุงุณุชูุฑุงุฏ ุงููุญุฏุงุช ุงูุฌุฏูุฏุฉ ูู ุงููุณุงุฑ ุงููุจุงุดุฑ - ูุญุฏุซ
from device_manager import get_device_info, setup_cuda_environment
from model_loader import load_whisper_model
from file_processor import ProcessController, process_uploaded_file, process_youtube_url, translate_to_arabic
from ui_components import (
    display_progress_indicator, display_results, render_about_tab,
    render_file_upload_section, render_youtube_section, 
    render_model_selection, render_control_buttons
)
from businessLogic import ProgressState

# ุฅุนุฏุงุฏ ุจูุฆุฉ CUDA ุนูุฏ ุงูุชุญููู
print("๐ง ุฌุงุฑู ุฅุนุฏุงุฏ ุจูุฆุฉ CUDA ู cuDNN...")
cudnn_available, paths_added = setup_cuda_environment()
if cudnn_available:
    print("โ ุชู ุชูุนูู cuDNN ุจูุฌุงุญ!")
else:
    print("โน๏ธ ุงููุธุงู ูุนูู ุนูู CPU ุจููุงุกุฉ ุนุงููุฉ")

# ุชููุฆุฉ ุญุงูุฉ ุงูุฌูุณุฉ
def initialize_session_state():
    """ุชููุฆุฉ ุฌููุน ูุชุบูุฑุงุช ุงูุฌูุณุฉ"""
    session_defaults = {
        'original_text': None,
        'translated_text': None,
        'process_running': False,
        'process_stopped': False,
        'stop_requested': False,
        'progress_state': None,
        'current_progress': 0,
        'current_stage': "",
        'stage_details': "",
        'translating': False,
        'controller': ProcessController(),
        'device_info': None  # ุฅุถุงูุฉ ุชุฎุฒูู ูุนูููุงุช ุงูุฌูุงุฒ
    }
    
    for key, value in session_defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def progress_callback(progress_state):
    """ุฏุงูุฉ callback ูุชุญุฏูุซ ุญุงูุฉ ุงูุชูุฏู"""
    st.session_state.progress_state = progress_state
    st.session_state.current_progress = progress_state.progress
    st.session_state.current_stage = progress_state.current_stage
    st.session_state.stage_details = progress_state.stage_details

def translation_progress_callback(message):
    """ุฏุงูุฉ callback ุฎุงุตุฉ ุจุงูุชุฑุฌูุฉ"""
    st.session_state.current_stage = "ุชุฑุฌูุฉ"
    st.session_state.stage_details = message

def start_processing(uploaded_file, url, model, cached_model, device_info):
    """ุจุฏุก ุนูููุฉ ุงูุชุญููู ุจุงุณุชุฎุฏุงู ุงููููุฐุฌ ุงููุฎุจุฃ"""
    st.session_state.process_running = True
    st.session_state.process_stopped = False
    st.session_state.stop_requested = False
    st.session_state.controller.should_stop = False
    st.session_state.progress_state = None
    st.session_state.current_progress = 0
    st.session_state.current_stage = ""
    st.session_state.stage_details = ""
    st.session_state.translating = False
    
    # ุงุณุชุฎุฏุงู ุงููููุฐุฌ ุงููุฎุจุฃ ุจุฏูุงู ูู ุชุญููู ุฌุฏูุฏ
    if cached_model is None:
        st.error("โ ุงููููุฐุฌ ุบูุฑ ูุญูู - ูุฑุฌู ุงููุญุงููุฉ ูุฑุฉ ุฃุฎุฑู")
        st.session_state.process_running = False
        return
    
    # ุชุดุบูู ุงููุนุงูุฌุฉ ูุจุงุดุฑุฉ
    if uploaded_file:
        original_text, message = process_uploaded_file(
            uploaded_file, cached_model, device_info,  # ุชูุฑูุฑ cached_model ุจุฏูุงู ูู model
            progress_callback, st.session_state.controller
        )
        st.session_state.original_text = original_text
        if message:
            if "โ" in message:
                st.success(message)
            elif "โ" in message:
                st.error(message)
    elif url:
        original_text, message = process_youtube_url(
            url, cached_model, device_info,  # ุชูุฑูุฑ cached_model ุจุฏูุงู ูู model
            progress_callback, st.session_state.controller
        )
        st.session_state.original_text = original_text
        if message:
            if "โ" in message:
                st.success(message)
            elif "โ" in message:
                st.error(message)
    
    # ุชุญุฏูุซ ููุงุฆู ูุงุญุฏ ููุท ุนูุฏ ุงูุงูุชูุงุก
    st.session_state.process_running = False
    st.rerun()

def stop_processing():
    """ุฅููุงู ููุฑู ููุนูููุฉ"""
    st.session_state.stop_requested = True
    st.session_state.controller.request_stop()
    st.error("๐ ุชู ุทูุจ ุงูุฅููุงู - ุฌุงุฑู ุฅููุงู ุงูุนูููุฉ...")
    st.session_state.process_running = False
    st.rerun()

def reset_session():
    """ุฅุนุงุฏุฉ ุชุนููู ุงูุฌูุณุฉ ุจุงููุงูู"""
    st.session_state.original_text = None
    st.session_state.translated_text = None
    st.session_state.process_running = False
    st.session_state.process_stopped = False
    st.session_state.stop_requested = False
    st.session_state.controller.should_stop = False
    st.session_state.progress_state = None
    st.session_state.current_progress = 0
    st.session_state.current_stage = ""
    st.session_state.stage_details = ""
    st.session_state.translating = False
    st.session_state.device_info = None
    st.rerun()

def main():
    st.title("๐ฅ Video2Text - ุชุญููู ุงูููุฏูู ุฅูู ูุต")
    
    # ุงูุญุตูู ุนูู ูุนูููุงุช ุงูุฌูุงุฒ ูุฑุฉ ูุงุญุฏุฉ ููุท
    if st.session_state.device_info is None:
        st.session_state.device_info = get_device_info()
    
    device_info = st.session_state.device_info
    
    # ุนุฑุถ ูุนูููุงุช ุงููุธุงู
    with st.expander("โน๏ธ ูุนูููุงุช ุงููุธุงู ูุงูุฃุฏุงุก", expanded=False):
        st.write(f"**{device_info['icon']} ูุถุน ุงูุชุดุบูู:** {device_info['reason']}")
        st.write(f"**๐ก ูุตูุญุฉ ุงูุฃุฏุงุก:** {device_info['performance_tip']}")
        st.write(f"**๐ฏ ุงูููุงุฐุฌ ุงูููุตู ุจูุง:** {', '.join(device_info['recommended_models'])}")
        st.write(f"**โก ููุน ุงูุญุณุงุจ:** {device_info['compute_type']}")
        st.write("**๐พ ุงููุฒุงูุง:** โก ุฃุณุฑุน 4x | ๐พ ุฐุงูุฑุฉ ุฃูู | ๐ ุชุญููู ููุฑู")
        
        # ุนุฑุถ ุญุงูุฉ cuDNN ุฅุฐุง ูุงู GPU ููุนู
        if device_info['device'] == 'cuda':
            st.success("โ GPU ููุนู ูุน cuDNN - ุณุฑุนุฉ ูุญุณูุฉ!")
        elif "cuDNN" in device_info['reason']:
            st.warning("๐ซ ูู ุจุชุซุจูุช cuDNN ูุชูุนูู GPU")
        else:
            st.info("๐ป CPU ูุน INT8 - ุฃุฏุงุก ูุชูุงุฒู")
    
    # ุชุจููุจุงุช ุงูุชููู
    tab1, tab2 = st.tabs(["๐ ุชุญููู ุงูููุฏูู", "โน๏ธ ุนู ุงูุชุทุจูู"])
    
    with tab1:
        # ุฒุฑ ุชุญุฏูุซ ูุฏูู ููุท
        if st.session_state.process_running:
            if st.button("๐ ุชุญุฏูุซ ุงููุงุฌูุฉ", type="secondary"):
                st.rerun()
        
        # ุนุฑุถ ุญุงูุฉ ุงูุชูุฏู ุฅุฐุง ูุงูุช ุงูุนูููุฉ ุฌุงุฑูุฉ
        if st.session_state.process_running:
            st.subheader("๐ ุญุงูุฉ ุงูุชูุฏู")
            display_progress_indicator(
                st.session_state.process_running,
                st.session_state.progress_state,
                st.session_state.current_progress,
                st.session_state.current_stage,
                st.session_state.stage_details
            )
            
            if st.session_state.stop_requested:
                st.error("๐ ุฌุงุฑู ุฅููุงู ุงูุนูููุฉ...")
        
        st.write("ููููู ุฑูุน ููู ููุฏูู ูุญูู ุฃู ุฅุฏุฎุงู ุฑุงุจุท ููุชููุจ")
        
        # ุงุณุชุฎุฏุงู ุงูููููุงุช ุงูุฌุฏูุฏุฉ
        uploaded_file = render_file_upload_section()
        url = render_youtube_section()
        model = render_model_selection()
        
        # ุชุญููู ุงููููุฐุฌ ุงููุฎุจุฃ ุนูุฏ ุงุฎุชูุงุฑ ุงููููุฐุฌ
        cached_model = load_whisper_model(model, device_info)
        
        # ูุต ุฅุฑุดุงุฏู ุฅุถุงูู ููููุฏูููุงุช ุงููุจูุฑุฉ
        if uploaded_file and (uploaded_file.size / (1024 * 1024)) > 500:
            st.write("๐ก **ููุชุญููู ุงูุณุฑูุน**: ุงุฎุชุฑ `tiny` ุฃู `base` - **ููุฌูุฏุฉ ุงูุนุงููุฉ**: ุงุฎุชุฑ `small` ุฃู `medium`")
        else:
            st.write("ุงูููุงุฐุฌ ุงูุฃุตุบุฑ ุฃุณุฑุน ูููู ุฃูู ุฏูุฉุ ุงูููุงุฐุฌ ุงูุฃูุจุฑ ุฃุจุทุฃ ูููู ุฃูุซุฑ ุฏูุฉ")
        
        # ุฃุฒุฑุงุฑ ุงูุชุญูู ุงูุฑุฆูุณูุฉ
        has_file_or_url = uploaded_file or url
        button_action = render_control_buttons(
            st.session_state.process_running,
            st.session_state.stop_requested,
            has_file_or_url,
            cached_model
        )
        
        if button_action == "start":
            start_processing(uploaded_file, url, model, cached_model, device_info)
        elif button_action == "stop":
            stop_processing()
        elif button_action == "reset":
            reset_session()
        
        # ุนุฑุถ ุงููุชุงุฆุฌ ุฅุฐุง ูุงูุช ููุฌูุฏุฉ
        if st.session_state.original_text:
            translate_requested = display_results(
                st.session_state.original_text,
                st.session_state.translated_text,
                st.session_state.translating,
                st.session_state.controller
            )
            
            if translate_requested:
                st.session_state.translating = True
                try:
                    with st.spinner("ุฌุงุฑู ุงูุชุฑุฌูุฉ... ูุฏ ุชุณุชุบุฑู ุจุถุน ุซูุงูู"):
                        st.session_state.translated_text = translate_to_arabic(
                            st.session_state.original_text, 
                            st.session_state.controller,
                            translation_progress_callback  # โ ุฅุถุงูุฉ progress_callback
                        )
                        st.success("โ ุชูุช ุงูุชุฑุฌูุฉ ุจูุฌุงุญ!")
                except Exception as e:
                    st.error(f"โ ุญุฏุซ ุฎุทุฃ ูู ุงูุชุฑุฌูุฉ: {e}")
                finally:
                    st.session_state.translating = False
                st.rerun()
        
        # ูุณู ุงููุณุงุนุฏุฉ ููููุฏูููุงุช ุงููุจูุฑุฉ
        if uploaded_file and (uploaded_file.size / (1024 * 1024)) > 500:
            with st.expander("๐ก ูุตุงุฆุญ ููููุฏูููุงุช ุงููุจูุฑุฉ"):
                st.write("""
                **ููููุฏูููุงุช ุงูุฃูุจุฑ ูู 500 MB:**
                
                - ๐ **ููุณุฑุนุฉ**: ุงุณุชุฎุฏู `tiny` ุฃู `base`
                - โก **ููุชูุงุฒู**: ุงุณุชุฎุฏู `small` 
                - ๐ **ููุฏูุฉ**: ุงุณุชุฎุฏู `medium` (ุจุทูุก ุฌุฏุงู)
                - โ **ุชุฌูุจ**: `large` (ูุฏ ููุดู ูุงุณุชููุงู ุงูุฐุงูุฑุฉ)
                
                **ูุฑุงุญู ุงูุชุญููู:**
                1. ๐ต ุงุณุชุฎุฑุงุฌ ุงูุตูุช ูู ุงูููุฏูู (25%)
                2. ๐ค ุงุณุชุฎุฏุงู ุงููููุฐุฌ ุงููุฎุจุฃ (0%) - โก ููุฑู  
                3. ๐ ุชุญููู ุงูุตูุช ุฅูู ูุต (75%)
                4. โ ุงูุงูุชูุงุก ูุงููุนุงูุฌุฉ (100%)
                
                **ููุงุญุธุฉ:** ููููู ุฅููุงู ุงูุนูููุฉ ูู ุฃู ููุช ุจุงุณุชุฎุฏุงู ุฒุฑ โน๏ธ
                """)
    
    with tab2:
        render_about_tab()
    
    # ูุณู ุญููู ุงูููููุฉ
    st.markdown("---")
    st.markdown("**ยฉ 2025 Video2Text - ุชู ุงูุชุทููุฑ ุจูุงุณุทุฉ Muhammed ElOmer**")

if __name__ == "__main__":
    initialize_session_state()
    main()